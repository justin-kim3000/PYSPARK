{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e49ab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96644767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b16e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a42c3800",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/Users/heewonkim/pySpark/state.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87853d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/22 16:31:24 WARN Utils: Your hostname, Heewonui-MacBookPro.local resolves to a loopback address: 127.0.0.1; using 192.168.0.11 instead (on interface en0)\n",
      "22/11/22 16:31:24 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/heewonkim/opt/anaconda3/lib/python3.7/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/11/22 16:31:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    spark = (SparkSession\n",
    "        .builder\n",
    "        .appName(\"PythonMnMCount\")\n",
    "        .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0546305b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: mnmcount <file>\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heewonkim/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"Usage: mnmcount <file>\", file=sys.stderr)\n",
    "        sys.exit(-1)\n",
    "\n",
    "    spark = (SparkSession\n",
    "        .builder\n",
    "        .appName(\"PythonMnMCount\")\n",
    "        .getOrCreate())\n",
    "    # get the M&M data set file name\n",
    "    mnm_file = sys.argv[1]\n",
    "    # read the file into a Spark DataFrame\n",
    "    mnm_df = (spark.read.format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .load(\"/Users/heewonkim/pySpark/state.csv\"))\n",
    "    mnm_df.show(n=5, truncate=False)\n",
    "\n",
    "    # aggregate count of all colors and groupBy state and color\n",
    "    # orderBy descending order\n",
    "    count_mnm_df = (mnm_df.select(\"State\", \"Color\", \"Count\")\n",
    "                    .groupBy(\"State\", \"Color\")\n",
    "                    .sum(\"Count\")\n",
    "                    .orderBy(\"sum(Count)\", ascending=False))\n",
    "\n",
    "    # show all the resulting aggregation for all the dates and colors\n",
    "    count_mnm_df.show(n=60, truncate=False)\n",
    "    print(\"Total Rows = %d\" % (count_mnm_df.count()))\n",
    "\n",
    "    # find the aggregate count for California by filtering\n",
    "    ca_count_mnm_df = (mnm_df.select(\"*\")\n",
    "                       .where(mnm_df.State == 'CA')\n",
    "                       .groupBy(\"State\", \"Color\")\n",
    "                       .sum(\"Count\")\n",
    "                       .orderBy(\"sum(Count)\", ascending=False))\n",
    "\n",
    "    # show the resulting aggregation for California\n",
    "    ca_count_mnm_df.show(n=10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e05119a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State|Color |Count|\n",
      "+-----+------+-----+\n",
      "|TX   |Red   |20   |\n",
      "|NV   |Blue  |66   |\n",
      "|CO   |Blue  |79   |\n",
      "|OR   |Blue  |71   |\n",
      "|WA   |Yellow|93   |\n",
      "+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnm_df = (spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(\"/Users/heewonkim/pySpark/mnm_dataset.csv\"))\n",
    "mnm_df.show(n=5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f1d8d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----------+\n",
      "|State|Color |sum(Count)|\n",
      "+-----+------+----------+\n",
      "|WY   |Brown |86110     |\n",
      "|WY   |Yellow|87800     |\n",
      "|WY   |Orange|87956     |\n",
      "|OR   |Yellow|88129     |\n",
      "|UT   |Green |88392     |\n",
      "|TX   |Blue  |88466     |\n",
      "|UT   |Brown |88973     |\n",
      "|CA   |Blue  |89123     |\n",
      "|OR   |Brown |89136     |\n",
      "|UT   |Yellow|89264     |\n",
      "|NV   |Red   |89346     |\n",
      "|CO   |Red   |89465     |\n",
      "|OR   |Green |89578     |\n",
      "|WA   |Blue  |89886     |\n",
      "|AZ   |Blue  |89971     |\n",
      "|UT   |Blue  |89977     |\n",
      "|NV   |Blue  |90003     |\n",
      "|AZ   |Red   |90042     |\n",
      "|NM   |Blue  |90150     |\n",
      "|OR   |Red   |90286     |\n",
      "|CA   |Orange|90311     |\n",
      "|OR   |Blue  |90526     |\n",
      "|TX   |Brown |90736     |\n",
      "|AZ   |Yellow|90946     |\n",
      "|CO   |Orange|90971     |\n",
      "|UT   |Red   |90995     |\n",
      "|WY   |Blue  |91002     |\n",
      "|NM   |Green |91160     |\n",
      "|NM   |Orange|91251     |\n",
      "|NV   |Green |91331     |\n",
      "|UT   |Orange|91341     |\n",
      "|NV   |Yellow|91390     |\n",
      "|WA   |Orange|91521     |\n",
      "|CA   |Red   |91527     |\n",
      "|AZ   |Orange|91684     |\n",
      "|WY   |Red   |91768     |\n",
      "|AZ   |Green |91882     |\n",
      "|AZ   |Brown |92287     |\n",
      "|TX   |Orange|92315     |\n",
      "|NV   |Brown |92478     |\n",
      "|NM   |Yellow|92747     |\n",
      "|WA   |Yellow|92920     |\n",
      "|WA   |Brown |93082     |\n",
      "|WA   |Red   |93332     |\n",
      "|CO   |Blue  |93412     |\n",
      "|NM   |Brown |93447     |\n",
      "|CA   |Green |93505     |\n",
      "|CO   |Brown |93692     |\n",
      "|CO   |Green |93724     |\n",
      "|TX   |Yellow|93819     |\n",
      "|NV   |Orange|93929     |\n",
      "|WY   |Green |94339     |\n",
      "|OR   |Orange|94514     |\n",
      "|NM   |Red   |94699     |\n",
      "|CO   |Yellow|95038     |\n",
      "|TX   |Red   |95404     |\n",
      "|TX   |Green |95753     |\n",
      "|CA   |Brown |95762     |\n",
      "|WA   |Green |96486     |\n",
      "|CA   |Yellow|100956    |\n",
      "+-----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_mnm_df = (mnm_df.select(\"State\", \"Color\", \"Count\")\n",
    "                .groupBy(\"State\", \"Color\")\n",
    "                .sum(\"Count\")\n",
    "                .orderBy(\"sum(Count)\"))\n",
    "count_mnm_df.show(n=60, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "857514b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "count_mnm_df.write.format(\"csv\").mode(\"append\").save(\"/Users/heewonkim/pySpark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0954e714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f3ba71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/Users/heewonkim/Desktop/python_data/number_one.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69302ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = true)\n",
      " |    |-- width: integer (nullable = true)\n",
      " |    |-- nChannels: integer (nullable = true)\n",
      " |    |-- mode: integer (nullable = true)\n",
      " |    |-- data: binary (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "images_df = spark.read.format(\"image\").load(image_dir)\n",
    "images_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9ddf273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+---------+----+\n",
      "|height|width|nChannels|mode|\n",
      "+------+-----+---------+----+\n",
      "|   145|  200|        3|  16|\n",
      "+------+-----+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "images_df.select(\"image.height\",\"image.width\",\"image.nChannels\",\"image.mode\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9fb8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
